Starting train_sign.py at Sun Jun 22 03:52:05 CEST 2025
/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
wandb: Currently logged in as: gdgvn (Continual_Learning-DAL) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.11
wandb: Run data is saved locally in /work/courses/csnlp/Team3/slt/wandb/run-20250622_035216-zmrgepbh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-haze-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/Continual_Learning-DAL/signvlm-fixed-phoenix-translation
wandb: üöÄ View run at https://wandb.ai/Continual_Learning-DAL/signvlm-fixed-phoenix-translation/runs/zmrgepbh
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1750557144.859697 3079618 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5
I0000 00:00:1750557144.944353 3079693 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 570.86.15), renderer: NVIDIA GeForce GTX 1080 Ti/PCIe/SSE2
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
W0000 00:00:1750557145.073126 3079688 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
W0000 00:00:1750557145.134298 3079685 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
W0000 00:00:1750557145.146715 3079690 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
W0000 00:00:1750557145.147940 3079684 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
W0000 00:00:1750557145.148536 3079680 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
W0000 00:00:1750557145.188539 3079674 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
W0000 00:00:1750557145.192997 3079692 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
W0000 00:00:1750557145.212831 3079691 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.
Loading SignVLMDynamic model...
Model loaded. Total parameters: 1,320,007,369
Trainable parameters: 84,192,969
Loading dataset...
Filtered out 6866 samples without frames
Training set size: 207
Validation set size: 23
Starting training...
Epoch 1:   0%|          | 0/52 [00:00<?, ?it/s]/work/scratch/tdieudonne/datasets/phoenix_simplified.py:180: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  motion = torch.load(motion_path, map_location="cpu")
/work/scratch/tdieudonne/datasets/phoenix_simplified.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  spatial = torch.load(spatial_path, map_location="cpu")
/work/scratch/tdieudonne/datasets/phoenix_simplified.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  landmarks = torch.load(landmark_path, map_location="cpu")
Epoch 1:   0%|          | 0/52 [00:03<?, ?it/s, loss=11.0343, lr=5.00e-07]Epoch 1:   2%|‚ñè         | 1/52 [00:03<02:59,  3.51s/it, loss=11.0343, lr=5.00e-07]W0000 00:00:1750557207.854772 3079690 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.
Epoch 1:   2%|‚ñè         | 1/52 [01:07<57:34, 67.74s/it, loss=11.0343, lr=5.00e-07]
Epoch [1/20], Batch [1/52], Loss: 11.0343, LR: 5.00e-07
  Sample target: und nun die wettervorhersage f√ºr morgen samstag den ersten mai...
Traceback (most recent call last):
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/serialization.py", line 850, in save
    _save(
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/serialization.py", line 1114, in _save
    zip_file.write_record(name, storage, num_bytes)
RuntimeError: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data/0: file write failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/work/scratch/tdieudonne/train_sign.py", line 452, in <module>
    main()
  File "/work/scratch/tdieudonne/train_sign.py", line 328, in main
    for batch_idx, batch in enumerate(progress_bar):
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 420, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/utils/data/dataset.py", line 420, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/work/scratch/tdieudonne/datasets/phoenix_simplified.py", line 187, in __getitem__
    motion, spatial, landmarks = self._compute_and_cache_features(video_id, frame_paths)
  File "/work/scratch/tdieudonne/datasets/phoenix_simplified.py", line 161, in _compute_and_cache_features
    atomic_save(spatial_feats, spatial_path)
  File "/work/scratch/tdieudonne/datasets/phoenix_simplified.py", line 26, in atomic_save
    torch.save(obj, tmp)
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/serialization.py", line 849, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/work/courses/csnlp/Team3/envs/csnlp/lib/python3.10/site-packages/torch/serialization.py", line 690, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:603] . unexpected pos 512 vs 406
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mbreezy-haze-37[0m at: [34mhttps://wandb.ai/Continual_Learning-DAL/signvlm-fixed-phoenix-translation/runs/zmrgepbh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250622_035216-zmrgepbh/logs[0m
